# Step 1: Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error

# Step 2: Load dataset
url = "https://raw.githubusercontent.com/Opensourcefordatascience/Data-sets/master/uber.csv"
df = pd.read_csv(url)

# Step 3: Data preprocessing
df = df.dropna()  # remove missing values
df = df[(df['fare_amount'] > 0) & (df['passenger_count'] > 0)]  # remove invalid data

# Step 4: Feature engineering â€” calculate distance
def distance(lat1, lon1, lat2, lon2):
    return np.sqrt((lat1 - lat2)**2 + (lon1 - lon2)**2)

df['distance'] = distance(df['pickup_latitude'], df['pickup_longitude'],
                          df['dropoff_latitude'], df['dropoff_longitude'])

# Keep only useful columns
df = df[['fare_amount', 'passenger_count', 'distance']]

# Step 5: Identify outliers (optional visualization)
sns.boxplot(df['fare_amount'])
plt.show()

# Step 6: Correlation
print(df.corr())

# Step 7: Split data
X = df[['passenger_count', 'distance']]
y = df['fare_amount']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 8: Linear Regression
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

# Step 9: Random Forest Regression
rf = RandomForestRegressor(random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

# Step 10: Evaluate models
def evaluate(y_true, y_pred, model_name):
    r2 = r2_score(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    print(f"{model_name} -> R2: {r2:.3f}, RMSE: {rmse:.3f}")

evaluate(y_test, y_pred_lr, "Linear Regression")
evaluate(y_test, y_pred_rf, "Random Forest Regression")
